{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Covid_Chest",
      "language": "python",
      "name": "covid_chest"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Analysis play around.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LovedeepB/211/blob/master/colab/Analysis_approach2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cb7886"
      },
      "source": [
        "# REMOVING CONFOUNDERS\n",
        "\n",
        "\n",
        "Will try two different strategies to try and remove the confounders using the GAN Model that is described in the paper that is linked below.   \n",
        "   - https://www.nature.com/articles/s41467-020-19784-9#Sec2"
      ],
      "id": "06cb7886"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtLE_3rplR-"
      },
      "source": [
        "# getting the sample data from kaggle \n",
        "!pip install -q kaggle "
      ],
      "id": "wYtLE_3rplR-",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9PGCbwntq4Q"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# upload the kaggle.json file\n",
        "files.upload()"
      ],
      "id": "H9PGCbwntq4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hvUDf3vFRqo"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "id": "4hvUDf3vFRqo",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6rjDPgRvc_X",
        "outputId": "4dcaacb2-ec9a-43e3-f7f9-98283380309f"
      },
      "source": [
        "!kaggle datasets download -d lovedeepbajaj/sample-data"
      ],
      "id": "x6rjDPgRvc_X",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample-data.zip to /content\n",
            " 91% 105M/115M [00:03<00:00, 50.6MB/s] \n",
            "100% 115M/115M [00:03<00:00, 35.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYPVy2rFvh-C",
        "outputId": "f9c2a7a6-1263-4137-a545-d2153a3cbf5e"
      },
      "source": [
        "# unziping the dataset \n",
        "!unzip sample-data.zip"
      ],
      "id": "VYPVy2rFvh-C",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sample-data.zip\n",
            "  inflating: data/test_data/dataset_1/negative/00000001_000.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000001_001.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000001_002.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000002_000.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_000.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_001.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_002.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_003.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_004.png  \n",
            "  inflating: data/test_data/dataset_1/negative/00000003_005.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000003_006.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000003_007.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000004_000.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_000.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_001.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_002.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_003.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_004.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_005.png  \n",
            "  inflating: data/test_data/dataset_1/positive/00000005_006.png  \n",
            "  inflating: data/test_data/dataset_2/negative/101103270798497222826083823719046670601_jw1fu2.png  \n",
            "  inflating: data/test_data/dataset_2/negative/126397712012687540784611673197697059691_fp0cu9.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964012373310883942009084123158919_00-069-064.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964012373310883942009181081546904_00-027-172.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964012558082906712010004133151165_00-119-134.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964012819207061112010316094555679_04-017-068.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964012948363412702011013123142008_00-125-030.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964013076187734852011291090122566_00-195-189.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964013200840352202011315131143616_01-032-099.png  \n",
            "  inflating: data/test_data/dataset_2/negative/216840111366964013217898866992011329134906098_01-027-105.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03044_ses-E06138_run-1_bp-chest_vp-ap_cr.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03044_ses-E06790_run-1_bp-chest_vp-pa_dx.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03044_ses-E07712_run-1_bp-chest_vp-ap_cr.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03045_ses-E06139_run-1_bp-chest_vp-ap_dx.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03045_ses-E06910_acq-1_run-1_bp-chest_vp-ll_dx.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03045_ses-E06910_acq-2_run-1_bp-chest_vp-ll_dx.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03046_ses-E06217_acq-1_run-1_bp-chest_vp-ap_cr.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03046_ses-E06217_acq-2_run-1_bp-chest_vp-ap_cr.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03046_ses-E06569_run-1_bp-chest_vp-ap_cr.png  \n",
            "  inflating: data/test_data/dataset_2/positive/sub-S03046_ses-E06791_run-1_bp-chest_vp-pa_dx.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b706bb4a"
      },
      "source": [
        "# importing in required libraries \n",
        "import cv2 \n",
        "import seaborn as sns \n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import matplotlib.pyplot as plt "
      ],
      "id": "b706bb4a",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e98bc854"
      },
      "source": [
        "# this function loads in the images and returns them to you as well as the label (covid-19 pos or covid-19 neg)\n",
        "# ONLY LOADING IN 10 IMAGES \n",
        "def get_images(image_dir, category, size, x_rays):\n",
        "    for img in listdir(image_dir)[:10]:\n",
        "        # getting the location of that image \n",
        "        location = join(image_dir, img)\n",
        "        \n",
        "        # reading in the image as a gray scale \n",
        "        temp = cv2.imread(location, cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        # resizing the image\n",
        "        temp = cv2.resize(temp, size)\n",
        "        \n",
        "        # normalizing the image \n",
        "        temp = temp/255\n",
        "        \n",
        "        # storing the image and the label of that image inside of data \n",
        "        x_rays.append([temp, category])"
      ],
      "id": "e98bc854",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504a094b"
      },
      "source": [
        "# location of the images for dataset 1\n",
        "dataset1_neg_location = \"data/test_data/dataset_1/negative\"\n",
        "dataset1_pos_location = \"data/test_data/dataset_1/positive\""
      ],
      "id": "504a094b",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d10ec0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76fc3af-8da3-4104-bbb6-32d30c00fc95"
      },
      "source": [
        "# will contain all of the x-rays\n",
        "data = []\n",
        "\n",
        "# the size of the image \n",
        "IMG_SIZE = (200, 200)\n",
        "\n",
        "\n",
        "# READING IN NEGATIVE IMAGES FOR DATASET 1\n",
        "get_images(dataset1_neg_location, 0, IMG_SIZE, data)\n",
        "    \n",
        "\n",
        "# READING IN POSITIVE IMAGES FOR DATASET 1\n",
        "get_images(dataset1_pos_location, 1, IMG_SIZE, data)\n",
        "\n",
        "\n",
        "# seeing how many pictures we have for dataset 1\n",
        "len(data)"
      ],
      "id": "4d10ec0b",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ba001d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0506ab-6c99-4047-f11a-6872828150c2"
      },
      "source": [
        "# seeing how many non covid-19 related images do we have \n",
        "len([img for img in data if img[1] == 0])"
      ],
      "id": "5ba001d2",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ca50875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea096558-56d6-417c-b5ec-bf08ab628ac2"
      },
      "source": [
        "# seeing how many covid-19 related images do we have \n",
        "len([img for img in data if img[1] == 1])"
      ],
      "id": "7ca50875",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d77e775d"
      },
      "source": [
        "# location of the images for dataset 2\n",
        "dataset2_neg_location = \"data/test_data/dataset_2/negative\"\n",
        "dataset2_pos_location = \"data/test_data/dataset_2/positive\""
      ],
      "id": "d77e775d",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "780e2159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dd9d0c-88c8-4700-dc06-082e78ed61f9"
      },
      "source": [
        "data2 = []\n",
        "# READING IN THE NEGATIVE IMAGES FOR DATASET 2\n",
        "get_images(dataset2_neg_location, 0, IMG_SIZE, data2)\n",
        "\n",
        "\n",
        "# READING IN THE POSITIVE IMAGES FOR DATASET 2\n",
        "get_images(dataset2_pos_location, 1, IMG_SIZE, data2)\n",
        "\n",
        "len(data2)"
      ],
      "id": "780e2159",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42fb4bc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8090de7-adff-412e-dfbe-923672c33229"
      },
      "source": [
        "# seeing how many non covid-19 related images do we have \n",
        "len([img for img in data2 if img[1] == 0])"
      ],
      "id": "42fb4bc7",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "745152df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145fdf60-8ea1-4e41-c094-296f004a3f66"
      },
      "source": [
        "# seeing how many covid-19 related images do we have \n",
        "len([img for img in data2 if img[1] == 1])"
      ],
      "id": "745152df",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746411e4"
      },
      "source": [
        "<br /> \n",
        "\n",
        "## METHOD 1\n",
        "\n",
        "__REMOVING BIAS ON THE DATA SOURCE LEVEL__   \n",
        "\n",
        "First thing to do is to figure out how the GAN Model that we are using works. This will allow us to determine what needs to be edited and what doesn't. "
      ],
      "id": "746411e4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXPSD5ppGY46",
        "outputId": "e57056f7-49be-41cd-804c-114e8e206da3"
      },
      "source": [
        "!pip install dcor"
      ],
      "id": "LXPSD5ppGY46",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dcor in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dcor) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from dcor) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dcor) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->dcor) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->dcor) (0.34.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7afa3f"
      },
      "source": [
        "# importing the required libraries \n",
        "\n",
        "# will need for creating the confounder prediction model or the confounder-free prediction model \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Flatten, Input, Layer, MaxPooling2D, Conv2D, Reshape\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "import tensorflow as tf\n",
        "\n",
        "# will need to create an array of zeros when training the GAN \n",
        "import numpy as np\n",
        "\n",
        "# using to read in the required files\n",
        "import pandas as pd\n",
        "import glob \n",
        "\n",
        "# using for the distance correlation calculation\n",
        "import dcor\n",
        "\n",
        "\n",
        "import sys\n",
        "import random "
      ],
      "id": "1d7afa3f",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eed514ce"
      },
      "source": [
        "# adversial loss for squared correlation (the one that the code uses by default)\n",
        "def correlation_coefficient_loss(y_true, y_pred):\n",
        "    x = y_true\n",
        "    y = y_pred\n",
        "    mx = K.mean(x)\n",
        "    my = K.mean(y)\n",
        "    xm, ym = x-mx, y-my\n",
        "    r_num = K.sum(tf.multiply(xm,ym))\n",
        "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym)))) + 1e-5\n",
        "    r = r_num / r_den\n",
        "\n",
        "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
        "    return K.square(r)"
      ],
      "id": "eed514ce",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65e81d64"
      },
      "source": [
        "# adversial loss for mse\n",
        "def inv_mse(y_true, y_pred):\n",
        "    mse_value = K.sum(K.square(y_true-y_pred))\n",
        "\n",
        "    return -mse_value"
      ],
      "id": "65e81d64",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMc6XZR8g2GU"
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        # three different types of Adam optimizers\n",
        "        optimizer = Adam(0.0001) # for the actual classification (after removing confounders)\n",
        "        optimizer_distiller = Adam(0.0002) # when we remove the confounders\n",
        "        optimizer_regressor = Adam(0.0002) # for the model that predicts the confounders\n",
        "\n",
        "        # THIS PORTION IS FOR PREDICTING THE CONFOUNDERS \n",
        "        # Build a naive feature encoder\n",
        "        input_image = Input(shape=(200,200,1), name='input_image')\n",
        "        \n",
        "        feature_dense_enc = Conv2D(2, activation='tanh', kernel_size=(3,3),padding='valid')(input_image)\n",
        "        feature_dense_enc = MaxPooling2D(pool_size=(2,2))(feature_dense_enc)\n",
        "        feature_dense_enc = Conv2D(4, activation='tanh', kernel_size=(3,3),padding='valid')(feature_dense_enc)\n",
        "        feature_dense_enc = MaxPooling2D(pool_size=(2,2))(feature_dense_enc)\n",
        "        feature_dense_enc = Conv2D(8, activation='tanh', kernel_size=(3,3),padding='valid')(feature_dense_enc)\n",
        "        feature_dense_enc = MaxPooling2D(pool_size=(2,2))(feature_dense_enc)\n",
        "        \n",
        "        feature_dense_enc = Flatten()(feature_dense_enc) \n",
        "        self.encoder = Model(input_image, feature_dense_enc)\n",
        "\n",
        "        # Build and compile the bias predictor (encoder fixed)\n",
        "        self.regressor = self.build_regressor()\n",
        "        self.regressor.compile(loss='mse', optimizer=optimizer_regressor)\n",
        "        \n",
        "        \n",
        "        # THIS PORTION IS FOR REMOVING THE CONFOUNDERS. ALSO USES THE BUILD_REGRESSOR FUNCTION TO REMOVE THE BIAS\n",
        "        # For the distillation model (removing bias) we will only train the encoder adversarially\n",
        "        self.regressor.trainable = False\n",
        "        cf = self.regressor(feature_dense_enc)\n",
        "        self.distiller = Model(input_image, cf)\n",
        "        self.distiller.compile(loss=correlation_coefficient_loss, optimizer=optimizer_distiller)\n",
        "        \n",
        "        # use the following for MSE-based adversairal training\n",
        "        #self.distiller.compile(loss=inv_mse, optimizer=optimizer_distiller)\n",
        "        \n",
        "        \n",
        "        # THIS IS WHERE THE ACTUAL CONFOUNDER FREE CLASSIFICATION TAKES PLACE\n",
        "        # Build and Compile the classifer (for the actual classification task) \n",
        "        input_feature_clf = Input(shape=(4232,), name='input_feature_dense') # needed to edit this \n",
        "        feature_clf = Dense(16, activation='tanh')(input_feature_clf)\n",
        "        prediction_score = Dense(1, name='prediction_score')(feature_clf)\n",
        "        self.classifier = Model(input_feature_clf, prediction_score)\n",
        "        \n",
        "        # Build the entire workflow\n",
        "        prediction_score_workflow = self.classifier(feature_dense_enc)\n",
        "        label_workflow = Activation('sigmoid', name='r_mean')(prediction_score_workflow)\n",
        "        self.workflow = Model(input_image, label_workflow)\n",
        "        self.workflow.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "    # A FUNCTION USED BY THE BIAS PREDICTION MODEL \n",
        "    def build_regressor(self):\n",
        "        inputs_x = Input(shape=(4232,)) # needed to edit this \n",
        "        feature = Dense(16, activation='tanh')(inputs_x)\n",
        "        cf = Dense(1)(feature)\n",
        "\n",
        "        return Model(inputs_x, cf)\n",
        "\n",
        "    \n",
        "    # THIS FUNCTION IS THE ONE WE CALL IN ORDER TO PASS IN THE REQUIRED DATA TO DO THE ANALYSIS \n",
        "    def train_cf(self, epochs, dataset1, dataset2, batch_size = 20, fold=0):\n",
        "        # these are the images and the labels from dataset 1 and dataset 2 \n",
        "        [train_img, label]  = dataset1\n",
        "        [test_img, test_label] = dataset2\n",
        "        \n",
        "        \n",
        "        # THIS WILL BE THE DISTANCE CORRELATION (FOR ME IT WILL BE ABOUT THE DIFFERENCE BETWEEN THE DATASETS)\n",
        "        dc_cf = np.zeros((int(epochs/10)+1,))\n",
        "        \n",
        "        # THIS WILL RUN FOR THE # OF EPOCHS YOU SET \n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # selecting half of the images from dataset 1 and half of the images from dataset 2 and then making the array random \n",
        "            combined_data = []\n",
        "\n",
        "\n",
        "            # putting all of the images from dataset1 and dataset2 in the combined dataset \n",
        "            for img in train_img:\n",
        "              combined_data.append(img)\n",
        "            for img in test_img:\n",
        "              combined_data.append(img)\n",
        "\n",
        "            # since the number of images we use from the combined dataset and the dataset 1 have to be the same size we are going to suffle them so we don't just get all the images from dataset1 \n",
        "            random.shuffle(combined_data)\n",
        "\n",
        "\n",
        "            # reshaping the data \n",
        "            combined_data = np.array(combined_data).reshape(-1, 200, 200,1)\n",
        "            data = np.array(train_img).reshape(-1, 200, 200,1)\n",
        "            test_data = np.array(test_img).reshape(-1, 200, 200,1)\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            # the images we will train the model on and teach it to remove these confounders\n",
        "            training_feature_ctrl_batch = combined_data\n",
        "            \n",
        "            \n",
        "            \n",
        "            # ---------------------\n",
        "            #  Train regressor (bias predictor)\n",
        "            # ---------------------\n",
        "            # flattening the dataset1 \n",
        "            cf_ctrl_batch = self.encoder.predict(np.array(data))\n",
        "            # flatten the combinedd_dataset images \n",
        "            encoded_feature_ctrl_batch = self.encoder.predict(training_feature_ctrl_batch[:20])\n",
        "            r_loss = self.regressor.train_on_batch(encoded_feature_ctrl_batch, cf_ctrl_batch)\n",
        "\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Disstiller (bias removal)\n",
        "            # ---------------------\n",
        "            g_loss = self.distiller.train_on_batch(training_feature_ctrl_batch[:20], cf_ctrl_batch) \n",
        "\n",
        "                     \n",
        "            # ---------------------\n",
        "            #  Train Encoder & Classifier (actual classification task)\n",
        "            # ---------------------\n",
        "            # the actually classification will be done using these images -> since the combined dataset contains 20 images we can use the whole of dataset1 which contains 20 images \n",
        "            training_feature_batch = data\n",
        "            # we want to predict covid vs non-covid for the actual classification\n",
        "            dx_batch = np.array(label)\n",
        "            # passing in dataset 1 images (training_feature_batch) as x and the label (covid vs non-covid) as dx_batch as y \n",
        "            c_loss = self.workflow.train_on_batch(training_feature_batch, dx_batch)\n",
        "            \n",
        "            # flipping the images \n",
        "            training_feature_batch = np.flip(training_feature_batch,1)\n",
        "            training_feature_ctrl_batch = np.flip(training_feature_ctrl_batch,1)\n",
        "\n",
        "            # repeat the process again but this time flip it \n",
        "            cf_ctrl_batch = self.encoder.predict(np.array(data))\n",
        "            encoded_feature_ctrl_batch = self.encoder.predict(training_feature_ctrl_batch[:20])\n",
        "            r_loss = self.regressor.train_on_batch(encoded_feature_ctrl_batch, cf_ctrl_batch)\n",
        "            g_loss = self.distiller.train_on_batch(training_feature_ctrl_batch[:20], cf_ctrl_batch)\n",
        "            c_loss = self.workflow.train_on_batch(training_feature_batch, dx_batch)\n",
        "            \n",
        "            \n",
        "            # Plot the training progress\n",
        "            if epoch % 10 == 0:\n",
        "                c_loss_test_1 = self.workflow.evaluate(np.array(test_data), np.array(test_label), verbose = 0, batch_size = batch_size)\n",
        "                \n",
        "                # feature dist corr DO NOT UNDERSTAND THIS PORTION \n",
        "                #features_dense = self.encoder.predict(train_data[train_label == 0],  batch_size = batch_size)\n",
        "                #dc_cf[int(epoch/10)] = dcor.u_distance_correlation_sqr(features_dense, train_data[train_label == 0])\n",
        "                \n",
        "                \n",
        "                \n",
        "                print (\"%d [Acc: %f  Test Acc: %f]\" % (epoch, c_loss[1], c_loss_test_1[1]))\n",
        "                sys.stdout.flush()\n",
        "                \n",
        "        # returning the predictions   \n",
        "        pred = self.workflow.predict(test_data)\n",
        "        \n",
        "        # return dist corr, learned features for both groups and the prediction and accuray progress of the model \n",
        "        return pred"
      ],
      "id": "qMc6XZR8g2GU",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6100b368"
      },
      "source": [
        "gan_cf = GAN()"
      ],
      "id": "6100b368",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f46392a7"
      },
      "source": [
        "# getting the labels and the images separate \n",
        "train_data = []\n",
        "train_label = []\n",
        "\n",
        "for img in data:\n",
        "    train_data.append(img[0])\n",
        "    train_label.append(img[1])\n",
        "\n",
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "for img2 in data2:\n",
        "    test_data.append(img2[0])\n",
        "    test_label.append(img2[1])"
      ],
      "id": "f46392a7",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96754720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2424b9b-7570-4635-d28a-0f18bb499f72"
      },
      "source": [
        "dataset1 = [train_data, train_label]\n",
        "dataset2 = [test_data, test_label]\n",
        "\n",
        "\n",
        "# getting the accuracy of the model \n",
        "y_pred = gan_cf.train_cf(epochs = 41, dataset1 = dataset1, dataset2= dataset2)"
      ],
      "id": "96754720",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [Acc: 0.500000  Test Acc: 0.500000]\n",
            "10 [Acc: 0.750000  Test Acc: 0.700000]\n",
            "20 [Acc: 0.800000  Test Acc: 0.700000]\n",
            "30 [Acc: 0.850000  Test Acc: 0.700000]\n",
            "40 [Acc: 0.850000  Test Acc: 0.700000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46KdOEfbx0a9"
      },
      "source": [
        "values = []\n",
        "\n",
        "for prediction in y_pred:\n",
        "  if prediction >= 0.50:\n",
        "    values.append(1)\n",
        "  else:\n",
        "    values.append(0)"
      ],
      "id": "46KdOEfbx0a9",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vilGIMze4vNz",
        "outputId": "4b2a2a9e-9648-420e-e514-6661a839c0aa"
      },
      "source": [
        "values"
      ],
      "id": "vilGIMze4vNz",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P_vd8aO6EiS",
        "outputId": "9e8a660a-c538-4ad1-947d-a39808a04454"
      },
      "source": [
        "test_label"
      ],
      "id": "_P_vd8aO6EiS",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGizV7On6Fwr"
      },
      "source": [
        ""
      ],
      "id": "tGizV7On6Fwr",
      "execution_count": null,
      "outputs": []
    }
  ]
}